- must handle persistent, detached, read-only and in-memory cases
- The act of serializing a persistent object is equivalent to detach, then serialize
	- the effect of this is make the objects coming back to be in a detached state
- detached objects should come back as detached
- in-memory objects should come back as in-memory
- read-only objects are either persisted, or in-memory
	- deserialization of persisted read-only objects retrieves the unique instance.
		- try to IO optimize this on a list deserialization
- two choices for navigation following:
	- navigation based, rooted at one point. just like reladomo deep fetches
		- a little harder to reuse/abstract out, but quite possible if the code is just like deep fetch.
	- No: class based. with max depth.
		- for each config, each class specifies what to navigate.
		- while this is interesting, it's not consistent with the existing deepFetch semantics
			- supporting this could mean supporting a different kind of deepFetch
				- only seems interesting for navigations that have loops
- inheritance
	- type 1
	- type 2
	- type 3
- annotations:
	- used for methods declared on the concrete classes
	- only support parameterless methods
	- @ReladomoSerialize(Class[]) where Class[] is a set of view classes (really, marker classes, used for type safe naming)

- generic serializer:
	- usually a framework, like gson, will call something like:
			serialize(reladomoObject, serializationContext)
		on a registered implementation of the serializer
	- to delegate, let's wrap serializationContext into a ReladomoSerializationContext
	- must register serializers for both reladomo objects and lists
	- exception handling: writer throws IOException
	
	ReladomoSerializationContext:
		- serialize(reladomoObject)
		- serialize(reladomoObject, List<Navigation)
		- is given a list of navigations to follow
			- this will come from the deep fetches on a list automatically
		- can exclude attributes
		- can use a named configuration
		- outputs links for the rest of the navigations
		- delegates to a writer:
			- always passes in the original object
			- writeStart(reladomoObject)
			- writeInt(reladomoObject, name, value), writeLong, ...
			- writeNull(reladomoObject, name)
			- writeList
			- writeLink(reladomoObject, linkName, linkAttributes, linkParams)
			- writeObject(reladomoObject, attrName, objectToWrite)
			- writeEnd(reladomoObject)
			- names starting with _rdo are reladomo internal
				- _rdoState: 1 (in-memory), 4 (detached), 100 (read-only)
				- _rdoClass: java class name
- done: Serialized<T Extends MithraObject> and SerialziedList<T extends MithraList>
	- universal wrappers that can be registered with serialization framworks (gson/jackson/etc)
- deal with parameterized relationships
	- no good way to do this in json. The best is probably a nested structure:
	
	{
		"productId": 7,
		synonymByType: {
			"cusip": {
				"type": "cusip",
				"value": "XYZ"
			},
			"isn": {
				"type": "isn",
				"value": "XYZ"
			}
		}
	}
	- requires navigating all of parameters together
	- further nesting will result if the method has multiple params
		- for json, serialization must be sorted in parameter repetition. e.g. method.p1a.p2a, then method.p1a.p2b, then method.p1c.p2a, etc.
	- if the parameter value is complex (e.g. a set), it all falls apart
- circular references: json can't really handle it without a custom de/serializer.
	- beyond the scope of the main serializer. There is enough info passed around to be implementable by a context/writer impl
- xml example:


- deserialization 
	- ReladomoDeserializationContext
		- startObject/endObject
		- startList/endList (only for top level?)
		- <Enum: Field, ToOneRelationship, ToManyRelationship, Unknown> startFieldOrRelationhip(name)
		- Attribute startField(name)
		- boolean startRelationship(name) (returns isToMany)
		- parseFieldFromString?
		- setField(<type> value) ?
		- setFieldNull
		- getAttributes
		- start/end listElements
		
		
- jackson:
	- extend JsonDeserializer (or StdDeserializer for more common functions)
		-  	deserialize(JsonParser p, DeserializationContext ctxt)
		    JsonToken jsonToken = parser.nextToken();
		Is passed JsonParser that is positioned over first token it is to handle, which is:

			the (only) token it is to handle, for scalar types
			opening START_ARRAY for JSON Array
			either START_ELEMENT or FIELD_NAME for JSON Object -- latter may occur when embedded type information for polymorphic type handling has been processed. 

			START_OBJECT
			END_OBJECT
			START_ARRAY
			END_ARRAY
			FIELD_NAME
			VALUE_EMBEDDED_OBJECT
			VALUE_FALSE
			VALUE_TRUE
			VALUE_NULL
			VALUE_STRING
			VALUE_NUMBER_INT
			VALUE_NUMBER_FLOAT

		JsonToken jsonToken = parser.nextToken();
		if(JsonToken.FIELD_NAME.equals(jsonToken)){
			String fieldName = parser.getCurrentName();
			System.out.println(fieldName);

			jsonToken = parser.nextToken();

			if("foo".equals(fieldName)){
				fooValue = parser.getValueAsString();
			} else if ("bar".equals(fieldName)){
				barValue = parser.getValueAsInt();
			}
		}
	- register via module

- gson:
	- two ways: stream or parsed tree
	- parsed tree:
		- implements JsonDeserializer
			deserialize(JsonElement json, Type type,
        		JsonDeserializationContext context) throws JsonParseException
		- register: GsonBuilder.registerTypeAdapter(Type, Object).
		
	- stream
		- extends TypeAdapter
		- read(JsonReader reader) throws IOException
			 reader.beginObject();
			 while (reader.hasNext()) {
			   String name = reader.nextName();
			   if (name.equals("id")) {
				 id = reader.nextLong();
			   } else if (name.equals("text")) {
				 text = reader.nextString();
			   } else if (name.equals("geo") && reader.peek() != JsonToken.NULL) {
				 geo = readDoublesArray(reader);
			   } else if (name.equals("user")) {
				 user = readUser(reader);
			   } else {
				 reader.skipValue();
			   }
			 }
			 reader.endObject();
		
